{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Mobility_trends.csv'\n",
    "\n",
    "columns = ['country_region', 'sub_region_1', 'sub_region_2', 'date', \n",
    "           'retail_and_recreation_percent_change_from_baseline', \n",
    "           'grocery_and_pharmacy_percent_change_from_baseline',\n",
    "           'parks_percent_change_from_baseline', 'transit_stations_percent_change_from_baseline',\n",
    "           'workplaces_percent_change_from_baseline', 'residential_percent_change_from_baseline']\n",
    "\n",
    "df = pd.read_csv(filename, usecols = columns)\n",
    "\n",
    "df = df.rename(columns={'country_region': 'country', 'sub_region_1': 'region',\n",
    "                        'sub_region_2': 'subregion',\n",
    "                        'retail_and_recreation_percent_change_from_baseline':'recreation',\n",
    "                        'grocery_and_pharmacy_percent_change_from_baseline':'grocery and pharmacy',\n",
    "                        'parks_percent_change_from_baseline': 'parks',\n",
    "                        'transit_stations_percent_change_from_baseline':'transit',\n",
    "                        'workplaces_percent_change_from_baseline': 'workplaces',\n",
    "                        'residential_percent_change_from_baseline': 'residential'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th>subregion</th>\n",
       "      <th>date</th>\n",
       "      <th>recreation</th>\n",
       "      <th>grocery and pharmacy</th>\n",
       "      <th>parks</th>\n",
       "      <th>transit</th>\n",
       "      <th>workplaces</th>\n",
       "      <th>residential</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-02-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-02-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-02-17</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-02-18</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-02-19</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                country region subregion        date  recreation  \\\n",
       "0  United Arab Emirates    NaN       NaN  2020-02-15         0.0   \n",
       "1  United Arab Emirates    NaN       NaN  2020-02-16         1.0   \n",
       "2  United Arab Emirates    NaN       NaN  2020-02-17        -1.0   \n",
       "3  United Arab Emirates    NaN       NaN  2020-02-18        -2.0   \n",
       "4  United Arab Emirates    NaN       NaN  2020-02-19        -2.0   \n",
       "\n",
       "   grocery and pharmacy  parks  transit  workplaces  residential  \n",
       "0                   4.0    5.0      0.0         2.0          1.0  \n",
       "1                   4.0    4.0      1.0         2.0          1.0  \n",
       "2                   1.0    5.0      1.0         2.0          1.0  \n",
       "3                   1.0    5.0      0.0         2.0          1.0  \n",
       "4                   0.0    4.0     -1.0         2.0          1.0  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column descriptions\n",
    "\n",
    "This dataset was collected on march 1st.\n",
    "\n",
    "**Country**: represents which country the data is about\n",
    "\n",
    "**sub_region_1** and **sub_region_2**: specify the region where this data takes place if available\n",
    "\n",
    "**date**: when the data was collected, on august 17 2020 the data collection strategy was refined, so we will prioritize data onwards from there\n",
    "\n",
    "The subsequent columns use a system of deviation from a baseline, which is calculated with the median value, for the corresponding day of the week, during the 5-week period Jan 3â€“Feb 6, 2020.\n",
    "\n",
    "**recreation**: Mobility trends for places like restaurants, cafes, shopping centers, theme parks, museums, libraries, and movie theaters.\n",
    "\n",
    "**grocery and pharmacy**: Mobility trends for places like grocery markets, food warehouses, farmers markets, specialty food shops, drug stores, and pharmacies.\n",
    "\n",
    "**parks**: Mobility trends for places like local parks, national parks, public beaches, marinas, dog parks, plazas, and public gardens.\n",
    "\n",
    "**transit**: Mobility trends for places like public transport hubs such as subway, bus, and train stations.\n",
    "\n",
    "**workplaces**: Mobility trends for places of work.\n",
    "\n",
    "**residential**: Mobility trends for places of residence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe has 4389190 rows\n"
     ]
    }
   ],
   "source": [
    "print(f'The dataframe has {np.shape(df)[0]} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country                  0.000000\n",
       "region                   1.700610\n",
       "subregion               16.634003\n",
       "date                     0.000000\n",
       "recreation              37.200850\n",
       "grocery and pharmacy    39.439145\n",
       "parks                   51.937829\n",
       "transit                 49.476464\n",
       "workplaces               4.565808\n",
       "residential             41.739410\n",
       "dtype: float64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*df.isna().sum()/4389190"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that percentually there are a lot of missing values, probably because of uncooperative countries. But no missing dates. Ideally we would like to use data from after august 17th and try to eliminate countries with excessive missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dates are strings, so first we need to convert them to datetime and then eliminate unecessary values. 196 days passed since august 17th, therefore we expect somewhere around that for each time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th>subregion</th>\n",
       "      <th>date</th>\n",
       "      <th>recreation</th>\n",
       "      <th>grocery and pharmacy</th>\n",
       "      <th>parks</th>\n",
       "      <th>transit</th>\n",
       "      <th>workplaces</th>\n",
       "      <th>residential</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-18</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-19</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-20</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-45.0</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-21</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-22</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>-44.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  country region subregion       date  recreation  \\\n",
       "185  United Arab Emirates    NaN       NaN 2020-08-18       -23.0   \n",
       "186  United Arab Emirates    NaN       NaN 2020-08-19       -23.0   \n",
       "187  United Arab Emirates    NaN       NaN 2020-08-20       -26.0   \n",
       "188  United Arab Emirates    NaN       NaN 2020-08-21       -33.0   \n",
       "189  United Arab Emirates    NaN       NaN 2020-08-22       -23.0   \n",
       "\n",
       "     grocery and pharmacy  parks  transit  workplaces  residential  \n",
       "185                  -7.0  -42.0    -42.0       -21.0         11.0  \n",
       "186                  -7.0  -42.0    -42.0       -21.0         11.0  \n",
       "187                  -9.0  -45.0    -43.0       -22.0         12.0  \n",
       "188                 -16.0  -56.0    -50.0       -14.0         10.0  \n",
       "189                  -9.0  -43.0    -44.0       -15.0          8.0  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:,'date']=pd.to_datetime(df['date']).values\n",
    "df = df.loc[df['date']>np.datetime64('2020-08-17').astype('datetime64[ns]')]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe has 2221991 rows\n"
     ]
    }
   ],
   "source": [
    "print(f'The dataframe has {np.shape(df)[0]} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country                  0.000000\n",
       "region                   1.706398\n",
       "subregion               16.404747\n",
       "date                     0.000000\n",
       "recreation              39.670413\n",
       "grocery and pharmacy    42.860885\n",
       "parks                   53.106696\n",
       "transit                 51.105202\n",
       "workplaces               4.008477\n",
       "residential             36.061172\n",
       "dtype: float64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*df.isna().sum()/2221991"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentage wise, the amount of missing data hasn't changed considerably. Which implies, as expected, that the missing values are due to countries/regions that don't collect properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring data by country and region\n",
    "\n",
    "Our goal is to eliminate empty values. In order to do this we must first detect regions and subregions that arent counting properly and eliminate them. So the process will be the following:\n",
    "\n",
    "Identify the countries, regions and sub regions. Starting from the sub regions we calculate the amount of NaN, if it is over a given % we discard that sub region. After eliminating all the empty sub-regions, we proceed to the regions that have NaN as their subregion, and then repeat for country.\n",
    "\n",
    "### Sub-regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 9899 sub-regions\n"
     ]
    }
   ],
   "source": [
    "subregions = df.subregion.unique()\n",
    "subregions = subregions[1:] # Removes NaN\n",
    "print(f'We have {len(subregions)} sub-regions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in subregions: print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how much information our subregional data is missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recreation              44.026393\n",
       "grocery and pharmacy    47.353752\n",
       "parks                   58.437161\n",
       "transit                 55.771182\n",
       "workplaces               4.424438\n",
       "residential             39.472909\n",
       "dtype: float64"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.loc[~df.subregion.isna()].isna().sum()*100/len(df.loc[~df.subregion.isna()]))[4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that subregional data is slightly worse than region and nationwide data. Which makes sense. Thus, we need to clean our subregional data. We believe that most of the missing data is contained in specific subregions. Thus, if we exclude the problematic subregions our database will have decent enough data to impute linear estimates.\n",
    "\n",
    "An example of the missing values in the sub region of Azul Partido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recreation               22\n",
      "grocery and pharmacy     46\n",
      "parks                    22\n",
      "transit                 108\n",
      "workplaces                4\n",
      "residential               2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print((df[df.subregion == 'Azul Partido'].isna().sum())[4:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering we have 196 days, we expect around 190 days in our time series. Therefore, in order to keep a sub region, we want it to have less than 38 (20% of 190) missing values in each mobility trend category. Azul Partido, for example, shouldn't be kept. This code iterates by subregion and writes the ones without enough data on an array. It takes A VERY LONG TIME to run. We also decided to filter any subregions with less than 170 dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unused_subregions = []\n",
    "#for i in subregions:\n",
    "    #if (df[df.subregion == i].isna().sum().nlargest(n=1)>38).any() or len(df[df.subregion == i]) < 170:\n",
    "        #unused_subregions.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ran it once so you don't have to and exported it to a .txt file. Just run the cells below to get it from the .txt please."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('unused_subregions', 'w') as f:\n",
    "    #for item in unused_subregions:\n",
    "        #f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file = open(\"unused_subregions\", \"r\")\n",
    "content = my_file.read()\n",
    "content_list = content.split(\"\\n\")\n",
    "my_file.close()\n",
    "unused_subregions = content_list[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "subregion_mask = df.subregion.isin(unused_subregions) # Creates a mask from the unused subregions\n",
    "subregion_df = df.loc[~subregion_mask] # Removes every unused subregion from the dataset\n",
    "subregion_df = subregion_df.loc[~subregion_df.subregion.isna()] # Removes every entry that doesnt have a subregion\n",
    "subregion_df = subregion_df.reset_index()\n",
    "subregion_df = subregion_df.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th>subregion</th>\n",
       "      <th>date</th>\n",
       "      <th>recreation</th>\n",
       "      <th>grocery and pharmacy</th>\n",
       "      <th>parks</th>\n",
       "      <th>transit</th>\n",
       "      <th>workplaces</th>\n",
       "      <th>residential</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>Comuna 1</td>\n",
       "      <td>2020-08-18</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>-73.0</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>Comuna 1</td>\n",
       "      <td>2020-08-19</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>Comuna 1</td>\n",
       "      <td>2020-08-20</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>-36.0</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>Comuna 1</td>\n",
       "      <td>2020-08-21</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-73.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>Comuna 1</td>\n",
       "      <td>2020-08-22</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-68.0</td>\n",
       "      <td>-70.0</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     country        region subregion       date  recreation  \\\n",
       "0  Argentina  Buenos Aires  Comuna 1 2020-08-18       -78.0   \n",
       "1  Argentina  Buenos Aires  Comuna 1 2020-08-19       -80.0   \n",
       "2  Argentina  Buenos Aires  Comuna 1 2020-08-20       -80.0   \n",
       "3  Argentina  Buenos Aires  Comuna 1 2020-08-21       -79.0   \n",
       "4  Argentina  Buenos Aires  Comuna 1 2020-08-22       -76.0   \n",
       "\n",
       "   grocery and pharmacy  parks  transit  workplaces  residential  \n",
       "0                 -32.0  -74.0    -73.0       -49.0         22.0  \n",
       "1                 -33.0  -79.0    -75.0       -51.0         23.0  \n",
       "2                 -36.0  -76.0    -75.0       -51.0         25.0  \n",
       "3                 -28.0  -75.0    -73.0       -50.0         26.0  \n",
       "4                  -9.0  -68.0    -70.0       -33.0         20.0  "
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subregion_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 2230 subregions\n"
     ]
    }
   ],
   "source": [
    "print(f'We have {len(subregion_df.subregion.unique())} subregions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The subregion dataframe has 423934 rows\n"
     ]
    }
   ],
   "source": [
    "print(f'The subregion dataframe has {np.shape(subregion_df)[0]} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recreation              3.238240\n",
       "grocery and pharmacy    4.511551\n",
       "parks                   7.540089\n",
       "transit                 4.726443\n",
       "workplaces              0.956045\n",
       "residential             0.474838\n",
       "dtype: float64"
      ]
     },
     "execution_count": 640,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(100*subregion_df.isna().sum()/423934)[4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the subregion dataset has been cleared quite nicely. \n",
    "\n",
    "Linearly interpolating missing values reduces the NaN percentage, but it doesn't work when a subregion's first value onwards is NaN. I think we have three choices, we can either remove subregions with missing values altogether, remove the missing rows or just pad with the nearest value. I'm not sure which to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in subregion_df.subregion.unique():\n",
    "    subregion_df.loc[subregion_df.subregion==i] = subregion_df.loc[subregion_df.subregion==i].interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recreation              2.368529\n",
       "grocery and pharmacy    3.465870\n",
       "parks                   6.360896\n",
       "transit                 4.094741\n",
       "workplaces              0.236593\n",
       "residential             0.001179\n",
       "dtype: float64"
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(100*subregion_df.isna().sum()/423934)[4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One solution is to cut all NaN blocks from above. So, to find where the largest NaN block ends:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-09-22 00:00:00')"
      ]
     },
     "execution_count": 643,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(subregion_df.loc[subregion_df.isnull().any(axis=1)].date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "subregion_df = subregion_df.loc[subregion_df.date>np.datetime64('2020-09-22').astype('datetime64[ns]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country                 0\n",
       "region                  0\n",
       "subregion               0\n",
       "date                    0\n",
       "recreation              0\n",
       "grocery and pharmacy    0\n",
       "parks                   0\n",
       "transit                 0\n",
       "workplaces              0\n",
       "residential             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subregion_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this our subregion dataset goes from 22.09.2020 to 23.02.2022, now we will ensure that all subregions have uninterrupted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = []\n",
    "for i in subregion_df.subregion.unique():\n",
    "    if len(subregion_df.loc[subregion_df.subregion == i]) != 154:\n",
    "        aux.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Toledo', 'Cuenca', 'Aurangabad', 'El Paso County', 'Suffolk County']"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "subregion_mask = subregion_df.subregion.isin(aux) # Creates a mask from the unused subregions\n",
    "subregion_df = subregion_df.loc[~subregion_mask] # Removes every unused subregion from the dataset\n",
    "subregion_df = subregion_df.reset_index()\n",
    "subregion_df = subregion_df.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 2225 uninterrupted subregions\n"
     ]
    }
   ],
   "source": [
    "print(f'We have {len(subregion_df.subregion.unique())} uninterrupted subregions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "subregion_df.to_csv(r'mobility trends datasets/subregion.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 1850 regions\n"
     ]
    }
   ],
   "source": [
    "regions = df.region.unique()\n",
    "regions = regions[1:]\n",
    "print(f'We have {len(regions)} regions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in regions: print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we already have information on the subregions, we can ignore them and only observe completely regional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th>date</th>\n",
       "      <th>recreation</th>\n",
       "      <th>grocery and pharmacy</th>\n",
       "      <th>parks</th>\n",
       "      <th>transit</th>\n",
       "      <th>workplaces</th>\n",
       "      <th>residential</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Abu Dhabi</td>\n",
       "      <td>2020-08-18</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Abu Dhabi</td>\n",
       "      <td>2020-08-19</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>-55.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Abu Dhabi</td>\n",
       "      <td>2020-08-20</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Abu Dhabi</td>\n",
       "      <td>2020-08-21</td>\n",
       "      <td>-31.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>-67.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Abu Dhabi</td>\n",
       "      <td>2020-08-22</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-41.0</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  country     region       date  recreation  \\\n",
       "560  United Arab Emirates  Abu Dhabi 2020-08-18       -23.0   \n",
       "561  United Arab Emirates  Abu Dhabi 2020-08-19       -24.0   \n",
       "562  United Arab Emirates  Abu Dhabi 2020-08-20       -26.0   \n",
       "563  United Arab Emirates  Abu Dhabi 2020-08-21       -31.0   \n",
       "564  United Arab Emirates  Abu Dhabi 2020-08-22       -22.0   \n",
       "\n",
       "     grocery and pharmacy  parks  transit  workplaces  residential  \n",
       "560                 -11.0  -35.0    -54.0       -21.0         11.0  \n",
       "561                 -11.0  -37.0    -55.0       -22.0         11.0  \n",
       "562                 -13.0  -42.0    -58.0       -22.0         12.0  \n",
       "563                 -19.0  -56.0    -67.0       -10.0         11.0  \n",
       "564                 -13.0  -41.0    -60.0       -13.0         10.0  "
      ]
     },
     "execution_count": 653,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_df = df.loc[df.subregion.isna()] # Remove sub-regionwide entries\n",
    "region_df = region_df.loc[~region_df.region.isna()] # Removes nationwide entries\n",
    "region_df = region_df.drop(['subregion'], axis=1)\n",
    "region_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recreation              19.251001\n",
       "grocery and pharmacy    22.041605\n",
       "parks                   28.602616\n",
       "transit                 30.255423\n",
       "workplaces               2.084226\n",
       "residential             20.687639\n",
       "dtype: float64"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(region_df.isna().sum()*100/len(region_df))[3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately the regional dataframe needs to undergo the same cleaning the subregional one underwent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "unused_regions = []\n",
    "for i in regions:\n",
    "    if (region_df[region_df.region == i].isna().sum().nlargest(n=1)>38).any() or len(region_df[region_df.region == i]) < 170:\n",
    "        unused_regions.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of a region with data collection issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recreation              18\n",
      "grocery and pharmacy    18\n",
      "parks                   18\n",
      "transit                 61\n",
      "workplaces               0\n",
      "residential             10\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print((region_df[region_df.region == 'Vraca'].isna().sum())[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th>date</th>\n",
       "      <th>recreation</th>\n",
       "      <th>grocery and pharmacy</th>\n",
       "      <th>parks</th>\n",
       "      <th>transit</th>\n",
       "      <th>workplaces</th>\n",
       "      <th>residential</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Abu Dhabi</td>\n",
       "      <td>2020-08-18</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Abu Dhabi</td>\n",
       "      <td>2020-08-19</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>-55.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Abu Dhabi</td>\n",
       "      <td>2020-08-20</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Abu Dhabi</td>\n",
       "      <td>2020-08-21</td>\n",
       "      <td>-31.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>-67.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Abu Dhabi</td>\n",
       "      <td>2020-08-22</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-41.0</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                country     region       date  recreation  \\\n",
       "0  United Arab Emirates  Abu Dhabi 2020-08-18       -23.0   \n",
       "1  United Arab Emirates  Abu Dhabi 2020-08-19       -24.0   \n",
       "2  United Arab Emirates  Abu Dhabi 2020-08-20       -26.0   \n",
       "3  United Arab Emirates  Abu Dhabi 2020-08-21       -31.0   \n",
       "4  United Arab Emirates  Abu Dhabi 2020-08-22       -22.0   \n",
       "\n",
       "   grocery and pharmacy  parks  transit  workplaces  residential  \n",
       "0                 -11.0  -35.0    -54.0       -21.0         11.0  \n",
       "1                 -11.0  -37.0    -55.0       -22.0         11.0  \n",
       "2                 -13.0  -42.0    -58.0       -22.0         12.0  \n",
       "3                 -19.0  -56.0    -67.0       -10.0         11.0  \n",
       "4                 -13.0  -41.0    -60.0       -13.0         10.0  "
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_mask = region_df.region.isin(unused_regions)\n",
    "region_df = region_df.loc[~region_mask]\n",
    "region_df = region_df.reset_index()\n",
    "region_df = region_df.drop(['index'], axis=1)\n",
    "region_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 1002 regions\n"
     ]
    }
   ],
   "source": [
    "print(f'We have {len(region_df.region.unique())} regions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this the regions that collect data inefficiently were eliminated. We only have to linearly estimate individual NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recreation              3.254676\n",
       "grocery and pharmacy    3.476311\n",
       "parks                   6.307149\n",
       "transit                 4.958430\n",
       "workplaces              0.905973\n",
       "residential             0.409657\n",
       "dtype: float64"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(100*region_df.isna().sum()/len(region_df))[3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolating missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in region_df.region.unique():\n",
    "    region_df.loc[region_df.region==i] = region_df.loc[region_df.region==i].interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recreation              2.612879\n",
       "grocery and pharmacy    2.809304\n",
       "parks                   5.309265\n",
       "transit                 4.449510\n",
       "workplaces              0.289386\n",
       "residential             0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(100*region_df.isna().sum()/len(region_df))[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-09-12 00:00:00')"
      ]
     },
     "execution_count": 662,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(region_df.loc[region_df.isnull().any(axis=1)].date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_df = region_df.loc[region_df.date>np.datetime64('2020-09-12').astype('datetime64[ns]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country                 0\n",
       "region                  0\n",
       "date                    0\n",
       "recreation              0\n",
       "grocery and pharmacy    0\n",
       "parks                   0\n",
       "transit                 0\n",
       "workplaces              0\n",
       "residential             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this our region dataset goes from 12.09.2020 to 23.02.2022, totaling 164 days of uninterrupted complete data for 1002 different regions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = []\n",
    "for i in region_df.region.unique():\n",
    "    if len(region_df.loc[region_df.region == i]) != 164:\n",
    "        aux.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cordoba', 'Punjab']"
      ]
     },
     "execution_count": 666,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_mask = region_df.region.isin(aux)\n",
    "region_df = region_df.loc[~region_mask]\n",
    "region_df = region_df.reset_index()\n",
    "region_df = region_df.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 1000 regions\n"
     ]
    }
   ],
   "source": [
    "print(f'We have {len(region_df.region.unique())} regions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_df.to_csv(r'mobility trends datasets/region.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 135 countries\n"
     ]
    }
   ],
   "source": [
    "countries = df.country.unique()\n",
    "print(f'We have {len(countries)} countries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in countries: print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "      <th>recreation</th>\n",
       "      <th>grocery and pharmacy</th>\n",
       "      <th>parks</th>\n",
       "      <th>transit</th>\n",
       "      <th>workplaces</th>\n",
       "      <th>residential</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>2020-08-18</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>2020-08-19</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>2020-08-20</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-45.0</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>2020-08-21</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>2020-08-22</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>-44.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  country       date  recreation  grocery and pharmacy  parks  \\\n",
       "185  United Arab Emirates 2020-08-18       -23.0                  -7.0  -42.0   \n",
       "186  United Arab Emirates 2020-08-19       -23.0                  -7.0  -42.0   \n",
       "187  United Arab Emirates 2020-08-20       -26.0                  -9.0  -45.0   \n",
       "188  United Arab Emirates 2020-08-21       -33.0                 -16.0  -56.0   \n",
       "189  United Arab Emirates 2020-08-22       -23.0                  -9.0  -43.0   \n",
       "\n",
       "     transit  workplaces  residential  \n",
       "185    -42.0       -21.0         11.0  \n",
       "186    -42.0       -21.0         11.0  \n",
       "187    -43.0       -22.0         12.0  \n",
       "188    -50.0       -14.0         10.0  \n",
       "189    -44.0       -15.0          8.0  "
      ]
     },
     "execution_count": 672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_df = df.loc[df.region.isna()]\n",
    "country_df = country_df.drop(['region', 'subregion'], axis=1)\n",
    "country_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recreation              2.160038\n",
       "grocery and pharmacy    2.088828\n",
       "parks                   3.040933\n",
       "transit                 2.115202\n",
       "workplaces              0.205718\n",
       "residential             1.345079\n",
       "dtype: float64"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(100*country_df.isna().sum()/len(country_df))[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing countries that don't collect data well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "unused_countries = []\n",
    "for i in countries:\n",
    "    if (country_df[country_df.country == i].isna().sum().nlargest(n=1)>38).any():\n",
    "        unused_countries.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "      <th>recreation</th>\n",
       "      <th>grocery and pharmacy</th>\n",
       "      <th>parks</th>\n",
       "      <th>transit</th>\n",
       "      <th>workplaces</th>\n",
       "      <th>residential</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>2020-08-18</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>2020-08-19</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>2020-08-20</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-45.0</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>2020-08-21</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>2020-08-22</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>-44.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                country       date  recreation  grocery and pharmacy  parks  \\\n",
       "0  United Arab Emirates 2020-08-18       -23.0                  -7.0  -42.0   \n",
       "1  United Arab Emirates 2020-08-19       -23.0                  -7.0  -42.0   \n",
       "2  United Arab Emirates 2020-08-20       -26.0                  -9.0  -45.0   \n",
       "3  United Arab Emirates 2020-08-21       -33.0                 -16.0  -56.0   \n",
       "4  United Arab Emirates 2020-08-22       -23.0                  -9.0  -43.0   \n",
       "\n",
       "   transit  workplaces  residential  \n",
       "0    -42.0       -21.0         11.0  \n",
       "1    -42.0       -21.0         11.0  \n",
       "2    -43.0       -22.0         12.0  \n",
       "3    -50.0       -14.0         10.0  \n",
       "4    -44.0       -15.0          8.0  "
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_mask = country_df.country.isin(unused_countries)\n",
    "country_df = country_df.loc[~country_mask]\n",
    "country_df = country_df.reset_index()\n",
    "country_df = country_df.drop(['index'], axis=1)\n",
    "country_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 125 different countries\n"
     ]
    }
   ],
   "source": [
    "print(f'We have {len(country_df.country.unique())} different countries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recreation              0.953911\n",
       "grocery and pharmacy    0.748769\n",
       "parks                   1.945432\n",
       "transit                 1.514633\n",
       "workplaces              0.071800\n",
       "residential             0.041028\n",
       "dtype: float64"
      ]
     },
     "execution_count": 677,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(100*country_df.isna().sum()/len(country_df))[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linearly interpolating missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in countries:\n",
    "    country_df.loc[country_df.country==i] = country_df.loc[country_df.country==i].interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recreation              0.728255\n",
       "grocery and pharmacy    0.557303\n",
       "parks                   1.576176\n",
       "transit                 1.278720\n",
       "workplaces              0.000000\n",
       "residential             0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 679,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(100*country_df.isna().sum()/len(country_df))[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the missing data starts from the first date and ends somewhere, we need to find the largest date with missing data. Which is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-09-10 00:00:00')"
      ]
     },
     "execution_count": 680,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(country_df.loc[country_df.isnull().any(axis=1)].date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df = country_df.loc[country_df.date>np.datetime64('2020-09-10').astype('datetime64[ns]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country                 0\n",
       "date                    0\n",
       "recreation              0\n",
       "grocery and pharmacy    0\n",
       "parks                   0\n",
       "transit                 0\n",
       "workplaces              0\n",
       "residential             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 682,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this our country dataset goes from 09.09.2020 to 23.02.2022, totaling 167 days of uninterrupted complete data for 125 different countries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = []\n",
    "for i in country_df.country.unique():\n",
    "    if len(country_df.loc[country_df.country == i]) != 166:\n",
    "        aux.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Egypt',\n",
       " 'Georgia',\n",
       " 'Ghana',\n",
       " 'Haiti',\n",
       " 'Jordan',\n",
       " 'South Korea',\n",
       " 'Kuwait',\n",
       " 'Morocco',\n",
       " 'Myanmar (Burma)',\n",
       " 'Nicaragua',\n",
       " 'Panama',\n",
       " 'Philippines',\n",
       " 'Qatar',\n",
       " 'Serbia',\n",
       " 'Tajikistan',\n",
       " 'Ukraine',\n",
       " 'Uruguay']"
      ]
     },
     "execution_count": 684,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_mask = country_df.country.isin(aux)\n",
    "country_df = country_df.loc[~country_mask]\n",
    "country_df = country_df.reset_index()\n",
    "country_df = country_df.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 108 different countries\n"
     ]
    }
   ],
   "source": [
    "print(f'We have {len(country_df.country.unique())} different countries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many countries were lost because we are trying to get uninterrupted data, so having all 167 days is essential. However, in this step we noticed a few countries like Egypt with over 400 days worth of data, despite only analyzing 166. The person imputting is probably imputting more than one country's worth of data into Egypt. So, because of this we lost 17 countries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    " x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
